#summary Evaluation summaries of packages, hardware, and processes under consideration in "the next version" of FabFi


The current FabFi version 4.0 includes billing capability, much improved networking monitoring, and the use and testing of Ubiquity devices, was deployed in 2010 in pilot in a community in Kenya. The pilot aimed to establish a self-sustaining-with-growth business that would build and maintain a free-to-fee network. Free-to-fee means their network was designed so that basic access to the internet and educational materials are free and they collect fees only for high speed unrestricted service. They have reached a critical mass of subscribers for self-sustainability and are now tackling growth. In the ensuing months our networks in Afghanistan and Kenya received much press and we have gotten a lot of technical volunteers to develop the system further.

FabFi version 5.0 (slated for late fall 2011) is predominately focused on scaling (to tens and hundreds of thousands of nodes and several hundreds of thousands of devices) and locally hosted educational/informational/contextual content. 

The code name for the version 5.0 project is “schoolnet” (no one likes the name but no one has a better idea – the next closest is free-edu-net). The software and system architecture allows anyone to connect for free for either low-speed, local, or educational content (that you can select and change as a community or a managed operator) while allowing people to chose to pay by-the-hour or by subscription for high speed unrestricted access. The hope is to be able to pay for the “free” with the “fee” parts.

With FabFi 5.0 we’re expecting to have a pretty great infrastructure but we haven’t forgotten that it’s only as good as the content and services available in the network. A substantial part of the development work has to do with the technologies of local caching and mirroring as well as the pedagogical aspects of the content itself.


<wiki:toc max_depth="2" />

= What are the hallmarks of "the next version"? =
  * massively larger number of nodes and devices (order 1000 to 2000)
  * possible large load of rsync/mirror traffic among content servers in the mesh

= Software: Routing =
The order of magnitude increase in the number of devices ...

=== protocol evaluation ===

|| || OLSR IPv4 || B.A.T.M.A.N. IPv4 || OLSR IPv6 || B.A.T.M.A.N. advanced IPv6 ||
|| Previous experience || FabFi, SWUG, BB4ALL || Afrimesh, VT || BB4ALL || Testbed ||
|| Node deploy sizes || ~1000 (Freifunk, Berlin) || ~50 (VT, Cape Town) || ~200 (BB4ALL, .za) || elektra sez <= 50  ||
|| User deploy sizes || ~5000 (Freifunk, Berlin) || ~100 (VT, Cape Town) || ~1000 (BB4ALL, .za) || unknown ||
|| Node Address assignment || Static/Dynamic || Static || RFC2462/OLSR || RFC2462 ||
|| Client Address Assignment || DHCP/NAT || DHCP/NAT || RFC2462/OLSR, niit || RFC2462 ||
|| Node Roaming || No || No || niit, RFC3775, ? || RFC3775 ||
|| Client Mesh Roaming || maybe (Layer3-Chilli) || No || niit, local bat0 || maybe ||
|| Network Segmentation || No || No || Yes || Yes ||
|| UserSpace Plugin API || Yes || No || Yes || No ||
|| Platform Availability || POSIX, WIN32 || LINUX || POSIX, WIN32 || LINUX ||
|| Layer 2 support || Plugin || No || Plugin || Yes ||
|| Programmable gateway selection || Yes || Limited || Yes || Limited ||
|| Ecosystem maturity || ~10 years || ~3 years || ~5 years || ~1 year ||
|| Duplicate addresses || Catastrophic || Catastrophic || Proactive detection || Unknown ||
|| Gateway Control || chilli, plugin, manual || chilli, manual || pepperspot, plugin, manual || chilli, manual ||
|| Management Messaging || plugin/transparent || kludge/limited || plugin/transparent  || kludge/limited ||

= Hardware: RF =
The FabFi projects have historically used Linksys WRT54GL or Ubiquity Nano and Pico stations, all of which are single band devices.

All ubiquiti preferred.  

core: central router.  w/ bridged 5g Nano.  Scales happily to 2000 addresses.

Local DNS served from all triangle nodes.

In ipv6, we expect OLSR to transparently handle local mesh node switches from one triangle gateway to another, while still advertising nodes properly to the non-mesh core.  

For redundancy to core, we have triangles advertising multiple network local addresses.  = statically configured redundancy.

Tests:
  * Do multiple network local address advertisements functionally route (see redundancy statement above)
  * Can we run AP+Adhoc on the same radio and still get and still get g-speed throughput?  
  * test client roaming on ipv6
  * 
== Open Mesh Dual Band (Model #) ==
evaluation goes here

= Hardware: Server =

= Hardware: Power =

= Hardware: Other =

= Software: Security / Captive portal

Considerations

  * OLSR Secure for node joins
  * Smart Gateway, possibly scripted for failover to tunnel out of mesh (this is potentially overkill since peer-to-peer would be totally unsecured)
  * 802.11x with an autoconfig page and dual SSIDs.  Radius provisions certs.



*** http://www.cappuccinopc.com
** Architecture
*** Access nodes
   * 802.11n devices benefit hugely from MIMO
   * Pico out
   * PowerAP N         -> http://ubnt.com/downloads/datasheets/powerapn/PowerAP_N_Datasheet.pdf
   * RouterStation
   * RouterStation Pro -> Embedded, POE, SDCard, 4x eth -> http://ubnt.com/rspro
*** Backbone routing
   *         Core: 5GHz Long-haul LOS infrastructure -> Nano5's Bridged into RouterStationPro
   *    Site Mesh: RouterStationPro
     - Service: OLSR
     - Service: Name resolution
     - Service: Routing redundancy HNA's
   * Access Nodes: PowerAP (alt. RouterStationPro where needed?)
     - test dual ssid -> Station/AdHoc
   * Circle Node: RouterStation = US$400 -> Pico + Nano = US$160 -> 2x Pico + Nano + Switch = US$300
                  Pico + PowerAP N + Nano = US$250
     - Connect to schoolnode via 5Ghz - Random Ch1
     - Local mesh: Mesh with other nodes in the area for redundancy -> 2.4/5 ? Undecided  Ch1 & Ch6
     - Access network: Connect to laptop via 2.4GHz Ch11
     - MIMO Antennas, no need share Antenna
   * Circle Node: Client Routing IPv6
     - ZeroConf
   * Circle Node: Client Routing IPv4
     - niit
     - gateway local content servers to ipv4 & dns
   * Radio SR71-A, 2.4/5, Long-range -> US$100
   * Get recommends on Atheros MiniPci's from WAPA
*** Auth/Tunneling/Security
   - Make sure server/gateway supports hardware crypt support for tunnels on eth's or Mobo
   - Access:
     Mesh Access Points: No Access Control - maybe anon 802.11x cert
          Triangle Node: Internet Gateway Access Control
           Route Access: Primary on router because if Internet Gateway falls over -> log in/log out
                         Validate @ gateway in case of rogue nodes
                         Insert client address directly in routing table
     Kinds: Time, Traffic
   - Auth:
     Database: Radius, replicate as required
     Mesh: None?
     Triangle Node: Some resources require authorization
                    Internet Gateway Auth is passworded
     Portal: Chilli? Probably not...
             802.11x -> maybe
             scripted portal -> maybe
     Routing: Cert determines which route endpoint router tunnels client to? Mesh-only tunnel endpoint,
                                                                             Internet tunnel end-point,
                                                                             Limited Internet tunnel end-point.
   - Traffic Accounting:
     Database: Radius, replicate as needed
         Mesh: No
      Gateway: Traffic Accounting, Time Accounting

*** Traffic Control:
    Access: Cap on individual client: 4096Mbps
      Mesh: No QOS -> Build capacity instead
   Gateway: Fair queing, per-application allocation, channel reservation?
            http://www.provu.co.uk/converged_ctx1000.html
            or other?

*** Performance & Monitoring:
   - % traffic of clients to mesh, % traffic of client to gateway
   - congested node bottlenecks
      - line color     -> LQ
      - line thickness -> b/w capacity
      - node color -> on/off
      - node shape -> device type
      - node coverage :-)
   - up/down time
   - throughput -> ntop/sflow (actual)
   - capacity   -> Assolo estimates capacity
   - SNMP: SNR, txpower, ETX, wireless packet loss, SSID's, software versions,
           OLSR LQ, OLSR Neighbor LQ's, OLSR Gateway, Net access,
           Interface throughput, Interface capacity, status of connected devices
           Power Monitoring via RS232 to Power Control Device
           longterm dev: Mesh MIB?
           FabFi Script that logs it at the moment
   - For MaximumKudos: UBNT style site surveys
   - Squid Stats (lightsquid)

*** Generic monitoring:
   - cacti
   - nagios?
   - AirControl?  (http://ubnt.com/forum/showpost.php?p=177840&postcount=1)
   - Content Server access stats -> Calamaris
   - Afrimesh for network map -> LONG TERM still they want openmesh

*** Bulk Node management
   - firmware updates w/ config retention
   - software versions, services etc.
   - memory disk-space/processor
   - change a config var for whole network (e.g. WEP key, SSID's)
      -> firmware can ship with postupgrade scripts

*** Server management
   - Puppet/Matahari

*** Provisioning:
   - physical deploy most by far
   - design of network -> i.e. what kind of node where
   - per node configuration -> script
   - LONGTERM OPTION per node configuration is auto-provisioned by network
   - Is there zeroconf DNS autoregistration on mesh?

*** Power Architecture
   - Simple:  Single device w/ POE support
              Single device w/ 5-12V canon
   - Complex: Fixed + Battery Backup + Solar + Power Control + POE Feed + POE Adaptor

*** NB: https://github.com/maruscia/ninux-airos-fw-oldstable